{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be precise, the integration of bacterial and gene data across datasets S12 and S13 could become challenging, particularly as the clustering approach scales. On the other hand, a tiered clustering model offers a more strategic solution for forward-looking predictive models.  \n",
    "- The logical next step was to incorporate a tree-based clustering, which will facilitate re-clustering based on gene-level data. A notable issue encountered was dealing with missing or incomplete bacterial abundance values, which posed difficulties in mapping protocols.  \n",
    "- In this instance, when clustering bacteria based on abundance, the predictability of gene expression emerged as a key challenge, especially given the potential volume of null outcomes from the gene-side predictions.  \n",
    "- The subsequent method of re-clustering bacterial features provided a stronger foundation for accurate gene expression prediction.  \n",
    "- This second-level clustering introduced a crucial function where bacterial features were prioritized, producing a more adaptable framework for predictive analysis (akin to multi-level regression techniques).  \n",
    "- Implementing clustering based on bacterial abundance was straightforward, but during the exploratory data analysis (EDA), a persistent issue arose with incomplete bacterial taxa labels. A future API update could address this by allowing for flexible labeling mechanisms that donâ€™t impact the integrity of the primary datasets.  \n",
    "- The tree-based clustering might present challenges for broader interpretation, but the algorithm has potential for in-depth breakdowns that can better explain the interactions between bacteria and gene expression outcomes.  \n",
    "- A more unconventional approach was taken in performing a second round of clustering on bacterial data, which deviated from standard protocol, but ensured all relevant data was parsed without loss of important features from S12 and S13. This ensured usability across multiple levels of analysis.  \n",
    "- The significance of outlier bacterial species has yet to be fully assessed. However, outliers are retained in the EDA, as their influence on gene expression models could offer critical insights in later stages of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from skbio.stats.distance import mantel\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import silhouette_score\n",
<<<<<<< HEAD
    "from sklearn.cluster import KMeans"
=======
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# smf model issue ??"
>>>>>>> 3e4131fb818ad876dfa5bc9897bd28b4ddb3bbcc
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
<<<<<<< HEAD
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/schoudhry/Desktop/Stable12.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load the data from CSV files using the provided paths\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m stable12 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/schoudhry/Desktop/Stable12.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Path for Stable12\u001b[39;00m\n\u001b[1;32m      3\u001b[0m stable13 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/schoudhry/Desktop/Stable13.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Path for Stable13\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Display the first row for both DataFrames to confirm the structure\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1662\u001b[0m     f,\n\u001b[1;32m   1663\u001b[0m     mode,\n\u001b[1;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1670\u001b[0m )\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/schoudhry/Desktop/Stable12.csv'"
     ]
    }
   ],
   "source": []
=======
     "data": {
      "text/plain": [
       "'\\nThe patients are coded b01 .. b0x\\nwith the genes being listed in the first column(column A)\\n\\ncheck the genes from s12 against the genes from \\nwhy use s6 \"The associations in the file are statistically significant, with a false \\ndiscovery rate (FDR) of less than 0.1. This means that the likelihood of identifying \\nfalse positives is controlled, ensuring that the associations are reliable \"\\n\\nFrom there\\ncheck the bacteria tree of each, focusing on the second in the tree\\nBacteria;Firmicutes;Clostridia;Clostridiales;Ruminococcaceae <- focus on Clostridia \\n\\ncheck the patients genes against the the genes with CRC from table s6\\nwith more occurances being more chance ??? -> prediction model ???? aimed to be made\\n\\n\\ncreate a dataframe with \\nS12 -> focusing on the gene(in column A)\\nS13 and S12 -> Row 1 (match up the values and re organize the table then print it out)\\nS12 and S13 -> once the values are matched, create a table from s12 that has the occurances of each gene\\nFor example column B2 -> would be:\\n        B01\\nTSPAN6   235\\nWhere TSPAN is the gene \\n235 the amount of the gene in patient B01\\n\\nthen from the S6 table\\ncheck which genes based on the amount of occurances would be likely to have CRC\\nthe taxa would be in the input feature(since it is Bacteria based(SECOND ON THE TREE))\\n\\nS13 and S6 -> check the bacteria against each other in the tables -> s6 and s13 focusingon the second in the tree\\nEx. -> Bacteria;Firmicutes;Clostridia;Clostridiales;Ruminococcaceae <- focus on Clostridia \\nS13 -> once organized alongside \\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Integrating S12 and S13\n",
    "# S12 is the List of Genes of the Patients(found in Column A)\n",
    "# Ex. -> B01 -> B03\n",
    "\n",
    "'''\n",
    "The patients are coded b01 .. b0x\n",
    "with the genes being listed in the first column(column A)\n",
    "\n",
    "check the genes from s12 against the genes from \n",
    "From there\n",
    "check the bacteria tree of each, focusing on the second in the tree\n",
    "Bacteria;Firmicutes;Clostridia;Clostridiales;Ruminococcaceae <- focus on Clostridia \n",
    "\n",
    "check the patients genes against the the genes with CRC from table s6\n",
    "with more occurances being more chance ??? -> prediction model ???? aimed to be made\n",
    "\n",
    "\n",
    "create a dataframe with \n",
    "S12 -> focusing on the gene(in column A)\n",
    "S13 and S12 -> Row 1 (match up the values and re organize the table then print it out)\n",
    "S12 and S13 -> once the values are matched, create a table from s12 that has the occurances of each gene\n",
    "For example column B2 -> would be:\n",
    "        B01x\n",
    "TSPAN6   235\n",
    "Where TSPAN is the gene \n",
    "235 the amount of the gene in patient B01\n",
    "\n",
    "\n",
    "\n",
    "S13 and S6 -> check the bacteria against each other in the tables -> s6 and s13 focusingon the second in the tree\n",
    "Ex. -> Bacteria;Firmicutes;Clostridia;Clostridiales;Ruminococcaceae <- focus on Clostridia \n",
    "S13 -> once organized alongside \n",
    "\n",
    "then from the S6 table\n",
    "check which genes based on the amount of occurances would be likely to have CRC\n",
    "the taxa would be in the input feature(since it is Bacteria based(SECOND ON THE TREE))\n",
    "\n",
    "from there check the gene through:\n",
    "with a high R-squared, low p-value, and valid after correction, could considered be a candidate for carrying CRC risk or involvement.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After fitting the model, look for significant gene predictions that are well explained by certain bacterial taxa.\n",
    "A gene whose expression is consistently predicted by microbial abundance, with a high R-squared, low p-value, and valid after correction, could be a candidate for carrying CRC risk or involvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV IMPORT(s)\n",
    "csv6 = '/Users/schoudhry/Desktop/IIT/Research/researchData/Supplementary Tables S6 S6.csv'\n",
    "csv12 = '/Users/schoudhry/Desktop/IIT/Research/researchData/StableS12.csv'\n",
    "csv13 = '/Users/schoudhry/Desktop/IIT/Research/researchData/Stable13.csv'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing runs\n",
    "\n",
    "\n",
    "s12_df = pd.read_csv(csv12)\n",
    "s13_df = pd.read_csv(csv13)\n",
    "\n",
    "\n",
    "def get_second_tree(bacteria_tree):\n",
    "    return bacteria_tree.split(';')[1] if ';' in bacteria_tree else None\n",
    "\n",
    "s13_df['Second_Taxonomy'] = s13_df.iloc[:, 0].apply(get_second_tree)\n",
    "\n",
    "s12_genes = s12_df.iloc[:, 0]\n",
    "\n",
    "\n"
   ]
>>>>>>> 3e4131fb818ad876dfa5bc9897bd28b4ddb3bbcc
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
